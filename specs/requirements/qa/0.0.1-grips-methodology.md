# GRIPS Requirements Q&A Session 0.0.1

**Phase**: 0.0 (Prototype)
**Date Started**: 2026-01-06
**Participants**: Dunkaroo Destroyer (Agent), Floppy Dog (Human)
**Purpose**: Requirements gathering for GRIPS methodology

---

## Question 1
**Asked by**: Dunkaroo Destroyer

**Question**: What's the core problem that GRIPS solves? Like, what goes wrong in spec-driven development with AI agents today that GRIPS is designed to fix?

**Answer**: I'd like to have an explicit framework for documentation, to avoid common pitfalls in using agents for spec-driven development. In GRIPS, all project documentation (requirements, architecture, design, status tracking, issue tracking, ADRs, everything other than code, actually including the code) has a designated place. Gone are the days of agents spamming new md files into random locations with temporal information. Gone are the days of implementations out of sync with requirements and design documents. Everything has its place and is constantly maintained as work is done. This means you can interact with the project at any level, and the rest of the artifacts and implementation will follow along to that change. For example, you can change a high level requirement such as adding a new feature, or report a bug having to do with a specific error message at the code level, or you can bring up a performance issue that affect the design at an architectural level, and that change is rolled out through changes to the rest of the project, from the highest level descriptions of the product down to the running code and test code. Agents working in the project have explicit instructions that ensure that they follow the methodology precisely rather than falling into a vibe of patching on top of patches and leaving cruft throughout the project artifacts.

---

## Question 2
**Asked by**: Dunkaroo Destroyer

**Question**: What are the specific layers or artifact types in this hierarchy? Like, from highest to lowest level, what's the structure? For example, is it something like:
- Requirements
- Architecture
- Design
- Implementation (code)
- Tests

Or is there a different/more detailed breakdown you have in mind?

**Answer**: Yes, that is the breakdown, though we may find there are more layers needed (at the high end, maybe someday we'll have a business case, or at the detailed end, perhaps we could expand someday into production infrastructure, observability, non-production infrastructure, CICD, etc.)

---

## Question 3
**Asked by**: Dunkaroo Destroyer

**Question**: How are these artifacts organized in the filesystem? Is it something like:
```
.grips/
├── requirements/
├── architecture/
├── design/
├── tests/
```
with code living in the normal project locations (`src/`, etc.)? Or is there a different organizational structure you're envisioning?

**Answer**: Let's classify architecture within design, but I'd like to add an implementation-plan to this. Also, let's make the directory not have a leading dot, because that makes it hidden in many user views. Also let's call the directory specs. This structure doesn't actually include the implementation (code) nor the tests -- they reside elsewhere, depending on the language and how the platform for that language prefers its structure. The implementation plan contains detailed step by step prompt plans for agentic coding.

---

## Question 4
**Asked by**: Dunkaroo Destroyer

**Question**: Where does the implementation plan sit in the hierarchy? Is it between design and code? And what's its purpose - like, is it the specific step-by-step plan for translating design into code, or something else?

**Answer**: (Answered in Question 3 follow-up - implementation plan contains detailed step by step prompt plans for agentic coding)

---

## Question 5
**Asked by**: Dunkaroo Destroyer

**Question**: When a change happens at one layer (say, a new requirement is added), how does GRIPS ensure propagation to the other layers? Is it:
a) Explicit agent instructions to update all affected layers in sequence?
b) Some kind of linking/traceability between artifacts (like requirement IDs referenced in design docs)?
c) The agent autonomously determines what needs updating?
d) Something else?

**Answer**: Some combination of those. I'd love to explore B. For now, let's stick with mostly A or C to instruct the agent to update the docs. Explicit linking can be a future enhancement if needed.

---

## Question 6
**Asked by**: Dunkaroo Destroyer

**Question**: For the linking/traceability approach - how do you envision the IDs working? For example:
- Do requirements get IDs like `REQ-001`, `REQ-002`?
- Do design docs reference those IDs explicitly?
- Does the implementation plan reference both requirement and design IDs?
- How granular are these links - per file, per section, per specific statement/feature?

What's your mental model for how an agent would follow these traces to know what to update?

**Answer**: (Deferred - sticking with A/C approach for now, explicit linking as future enhancement)

---

## Question 7
**Asked by**: Dunkaroo Destroyer

**Question**: When an agent is instructed to "update all affected layers" - is there a specific order they should follow? For example, if a bug is reported at the code level, does the agent work:
- Bottom-up (fix code → update implementation plan → update design → update requirements)?
- Top-down (update requirements → design → implementation plan → then fix code)?
- Or does it depend on the type of change?

**Answer**: Yes, I see these things as going in order, similar to what I've experienced in CASE tools back in the early 90s with e.g. CDM <--> LDM <--> PDM <--> physical database.

---

## Question 8
**Asked by**: Dunkaroo Destroyer

**Question**: When a change propagates, does it always go through all layers, or can it sometimes skip? For example:
- If someone fixes a typo in an error message, does that need to bubble up to requirements?
- If a new high-level feature is added to requirements, does it always require updates to design AND implementation plan before touching code?
- Or is there some concept of "scope of change" that determines how far to propagate?

**Answer**: I'd like to try it as strictly always going through all the layers.

---

## Question 9
**Asked by**: Dunkaroo Destroyer

**Question**: What's the file structure within each directory? For example, in `specs/requirements/`, is it:
a) One big `requirements.md` file?
b) Multiple files organized by feature/module (like `specs/requirements/authentication.md`, `specs/requirements/api.md`)?
c) Some other structure?

And does the same pattern apply to `specs/design/` and `specs/implementation-plan/`?

**Answer**: One big file always gets too big for any realistic project. Small projects should start with one file, but let's make explicit instructions for when and how to break up the files. When broken up, the original file (requirements.md) then contains high level info with pointers to the underlying files. All of the files should have standard naming so that nothing falls into some kind of custom, loosey-goosey proliferation of cruft.

---

## Question 10
**Asked by**: Dunkaroo Destroyer

**Question**: What triggers the split from single file to multiple files? Is it:
a) A specific size/line count threshold (e.g., "when requirements.md exceeds 500 lines")?
b) When certain organizational boundaries emerge (e.g., "when you have 3+ distinct features/modules")?
c) Agent discretion based on complexity?

And what's the standard naming when split? For example:
```
specs/requirements/
├── requirements.md          # Overview + pointers
├── authentication.md
├── data-model.md
└── api.md
```
Or some other pattern?

**Answer**: A - specific line count threshold of 1000 lines. About naming, they should be numbered by section. Everything should be numbered in outline numbering. This is what I've been experimenting with and it generally works, aside from agents' apparent difficulty in renumbering things.

---

## Question 11
**Asked by**: Dunkaroo Destroyer

**Question**: What's the specific line count threshold that triggers a split? And does the same threshold apply to all three directories (requirements, design, implementation-plan)?

**Answer**: (Answered in Question 10 - 1000 lines for all directories)

---

## Question 12
**Asked by**: Dunkaroo Destroyer

**Question**: When files are split by section number, what does that look like exactly? For example:

Option A:
```
specs/requirements/
├── requirements.md          # Overview + sections at high level
├── requirements-1.md        # Section 1 details
├── requirements-2.md        # Section 2 details
└── requirements-3.md        # Section 3 details
```

Option B:
```
specs/requirements/
├── requirements.md          # Overview
├── 1-feature-name.md
├── 2-another-feature.md
└── 3-third-feature.md
```

Or something else? And do the section numbers correspond across layers (like section 1 in requirements relates to section 1 in design)?

**Answer**: B - use format like `1-feature-name.md`, `2-another-feature.md`, etc.

---

## Question 13
**Asked by**: Dunkaroo Destroyer

**Question**: Do the section numbers and names stay synchronized across layers? For example, if you have:
```
specs/requirements/1-authentication.md
specs/design/1-authentication.md
specs/implementation-plan/1-authentication.md
```
Are they all describing the same feature at different abstraction levels? Or do the numbering schemes work independently in each directory?

**Answer**: I'm not sure yet. I think they may have to be numbered separately. One thing I can tell you is that any implementation worth doing is very likely going to be phased. There will be some prototype to start, then an MVP, then expansion from there. So the implementation plans are definitely phased explicitly.

---

## Question 14
**Asked by**: Dunkaroo Destroyer

**Question**: How is phasing reflected in the file structure? Is it something like:
```
specs/implementation-plan/
├── implementation-plan.md           # Overview
├── phase-1-prototype/
│   ├── 1-basic-auth.md
│   └── 2-simple-api.md
├── phase-2-mvp/
│   ├── 1-full-auth.md
│   └── 2-complete-api.md
└── phase-3-expansion/
    └── 1-advanced-features.md
```
Or is phasing tracked differently (like metadata in each file, or sections within files)?

**Answer**: That's correct - phases are first-class organizational units in implementation plans using subdirectories.

---

## Question 15
**Asked by**: Dunkaroo Destroyer

**Question**: What exactly goes into an implementation plan file? You mentioned they contain "detailed step-by-step prompt plans for agentic coding." Are these literally prompts the agent should execute in sequence?

**Answer**: [Provided detailed example of Feature 1: CoreData Infrastructure with steps 1.1-1.4 showing the exact format including Files Created/Modified, Prompt sections with detailed TASKS, REQUIREMENTS, BUILD AND VERIFY, Verification summaries, and Status tracking]

Additional notes:
- Not 100% sure about keeping status tracking inside the prompt plan docs, but that's how it's been done so far
- Could be useful to isolate status, but uncertain
- Most important: keep status as single source of truth for each item, avoid diary-like release notes (release notes are good but separate from status)
- All docs are drafted initially by agents
- Human provides review cycles using markdown with Critic Markup format annotations
- Using Obsidian markdown editor with plugins (might later be brought into GRIPS scope)
- Interaction to create documents is mostly Q&A sessions (like this one), during which agent documents the Q&A, then after that, agent drafts the various spec docs

---

## Question 16
**Asked by**: Dunkaroo Destroyer

**Question**: When these implementation plan prompts are written, who writes them initially - the agent or the human? And more specifically: when a new feature is added to requirements, does the agent automatically generate the corresponding design docs AND the implementation plan prompts? Or does the human write some layers and the agent fills in others?

**Answer**: (Answered in Question 15 follow-up - agents draft all docs initially, humans review with Critic Markup)

---

## Question 17
**Asked by**: Dunkaroo Destroyer

**Question**: Where in the directory structure should Q&A sessions live? For example:

Option A - Separate top-level directory:
```
specs/
├── qa-sessions/
│   ├── phase-1.0/
│   ├── phase-1.1/
│   └── phase-2.0/
├── requirements/
├── design/
└── implementation-plan/
```

Option B - Within implementation-plan (since they're tied to phases):
```
specs/implementation-plan/
├── phase-1-prototype/
│   ├── qa-1.0.md
│   ├── 1-feature.md
│   └── 2-feature.md
├── phase-2-mvp/
```

Option C - Something else?

**Answer**: C - We will have Q&A sessions for each phase within requirements, design, implementation-plan, etc. Although the requirements and design documents are not split by phase, the Q&A related to the changes in those docs is split by phase. Also, if we create any ADRs related to decision points along the way, those are also related to a specific phase of work. The first phase should be version 0.0, because we almost always start with a prototype.

---

## Question 18
**Asked by**: Dunkaroo Destroyer

**Question**: What does the directory structure look like for Q&A and ADRs within each layer? Something like:

```
specs/
├── requirements/
│   ├── requirements.md
│   ├── qa/
│   │   ├── 0.0-prototype.md
│   │   ├── 1.0-mvp.md
│   │   └── 2.0-expansion.md
│   └── adr/
│       ├── 0.0-some-decision.md
│       └── 1.0-another-decision.md
├── design/
│   ├── design.md
│   ├── qa/
│   │   ├── 0.0-prototype.md
│   │   └── 1.0-mvp.md
│   └── adr/
└── implementation-plan/
    ├── implementation-plan.md
    ├── phase-0-prototype/
    ├── phase-1-mvp/
    ├── qa/
    └── adr/
```

Or is there a different naming pattern? And when there are multiple Q&A sessions or ADRs within the same phase, how do you differentiate them (like `0.0.1`, `0.0.2`)?

**Answer**: Yes, and differentiate as 0.0.1, 0.0.2, etc.

---

## Question 19
**Asked by**: Dunkaroo Destroyer

**Question**: For our current Q&A session - this is about gathering requirements for GRIPS itself, and we're in the initial prototype phase (0.0). Should I create:
```
specs/requirements/qa/0.0.1-grips-methodology.md
```
And update it continuously as we go? Or is there a different naming convention you'd prefer for the Q&A files (since `0.0.1` doesn't tell you what the Q&A is about)?

**Answer**: Yes, please create it.

---

## Question 20
**Asked by**: Dunkaroo Destroyer

**Question**: You mentioned using Critic Markup for human review feedback. When the human provides feedback on agent-drafted docs, does the agent then:

a) Directly incorporate the feedback and remove the Critic Markup annotations?
b) Respond to each annotation one-by-one, accepting/rejecting changes?
c) Something else?

And should GRIPS specify a standard workflow for this review cycle?

**Answer**: The agent must evaluate the feedback to determine whether it requires additional feedback or review. If not, it makes the change and resolves (removes) the comment. If it's at all complicated or questionable (for example if the agent has to make a decision or recommendation) then the agent should make the changes requested and reply to the comment.

---

## Question 21
**Asked by**: Dunkaroo Destroyer

**Question**: We've talked a lot about the structure and workflow, but what actually goes INTO the `methodology.md` file that agents will load? Is it:

a) A detailed instruction manual that tells agents "when you see a requirement change, do X, Y, Z"?
b) A reference guide describing the structure and principles?
c) Executable rules/constraints that agents must follow?
d) Some combination?

And how prescriptive should it be - like step-by-step instructions vs. high-level principles?

**Answer**: All of the above. This might have to be broken down into multiple sections or files, if that is needed to guide the agents in doing this the right way.

---

## Question 22
**Asked by**: Dunkaroo Destroyer

**Question**: Since the methodology.md will contain instructions, reference material, and rules/constraints, how should it be organized? For example:

Option A - Single comprehensive file with clear sections:
```
.grips/methodology.md
  1. Overview & Principles
  2. Directory Structure Reference
  3. Workflow Procedures
  4. Rules & Constraints
  5. Examples
```

Option B - Split into multiple focused files:
```
.grips/
├── methodology.md (overview + links to others)
├── structure-reference.md
├── workflow-procedures.md
├── rules-constraints.md
└── examples.md
```

Option C - Something else?

And should these files also follow the 1000-line split rule?

**Answer**: A

---

## Question 23
**Asked by**: Dunkaroo Destroyer

**Question**: Let's talk about the concrete workflow. When a change comes in (like "add user authentication feature"), what are the specific steps an agent should follow? For example:

1. Create/update Q&A session document for current phase
2. Update requirements.md
3. Update design.md
4. Create/update implementation plan prompts
5. Execute implementation plan prompts
6. Verify all layers are in sync

Is that the right sequence? And should each step require explicit human approval, or does the agent work through multiple steps before pausing for review?

**Answer**: The sequence depends on what changes are needed to address the feedback or new request. Remember, the human can interact with the spec or code at any level, and the appropriate updates need to be made through the structure. There is not one pattern to follow to update something first, because the changes need to flow through each layer, starting where they are made.

---

## Question 24
**Asked by**: Dunkaroo Destroyer

**Question**: So the propagation is bidirectional based on where the change originates? For example:

- **Bug reported in code** → Flow UP: Update code → Update implementation plan → Update design → Update requirements
- **New requirement added** → Flow DOWN: Update requirements → Update design → Update implementation plan → Update code
- **Design change** → Flow BOTH ways: Update design → Flow UP to requirements AND DOWN to implementation plan/code

Is that correct? And does the agent need to explicitly identify "this change originated at the [X] layer, so I need to propagate up/down" before starting work?

**Answer**: Yes

---

## Question 25
**Asked by**: Dunkaroo Destroyer

**Question**: When an agent is propagating changes through the layers, at what points should it pause for human review? For example:

a) After completing ALL layer updates (show the human the full cascade of changes)?
b) After each individual layer update (get approval before moving to next layer)?
c) Only after drafting spec documents, but execute implementation plans automatically?
d) Something else?

And does this differ between upward vs. downward propagation?

**Answer**: The answer is (a) for requirements, design, and prompt plan, and all of those should be updated at the same time, go through one or more review cycles until approved, which could take multiple commits (one for each set of agent changes and one for each round of feedback). After approval (i.e. the human has no additional feedback) then the implementation starts. Implementation commits should include all the changes for one Step in the implementation plan, plus updates to status docs (and any small changes to design and requirements docs to clarify any findings from during the implementation). Alternatively, bug fixes and small feature tweaks can be made in separate commits, as guided by the human.

---

## Question 26
**Asked by**: Dunkaroo Destroyer

**Question**: We've been discussing the `specs/` directory for project artifacts, but earlier we talked about `.grips/methodology.md` for the GRIPS methodology itself. Should it be:

a) `.grips/methodology.md` (hidden directory for the framework itself, separate from project specs)?
b) `specs/methodology.md` (methodology lives alongside the project specs)?
c) Something else?

And when a user adds GRIPS to their project via `grips init`, what exactly gets created in their project directory?

**Answer**: The GRIPS methodology will be licensed, and it may have a different license than the user's project itself. In order to avoid those complexities, let's keep the methodology outside of the project somewhere. Let's create a `~/.grips` directory, and within there, let's create a versioned structure that holds the methodology itself. In the project, let's use a `METHODOLOGY.md` file that points to a specific version of the methodology within `~/.grips`.

---

## Question 27
**Asked by**: Dunkaroo Destroyer

**Question**: What does the versioned structure in `~/.grips` look like? For example:

Option A - Version directories:
```
~/.grips/
├── 0.1.0/
│   └── methodology.md
├── 0.2.0/
│   └── methodology.md
└── 1.0.0/
    └── methodology.md
```

Option B - Version files:
```
~/.grips/
├── methodology-0.1.0.md
├── methodology-0.2.0.md
└── methodology-1.0.0.md
```

Option C - Something else?

And what would the project's `METHODOLOGY.md` file contain - just a reference like `@~/.grips/1.0.0/methodology.md`?

**Answer**: A

---

## Question 28
**Asked by**: Dunkaroo Destroyer

**Question**: What should the project's `METHODOLOGY.md` file contain? Is it:

a) Just a reference to load the methodology: `@~/.grips/1.0.0/methodology.md`
b) A more descriptive file explaining the project uses GRIPS with the version, plus the reference
c) Something else?

And should this file be added to the project's CLAUDE.md (or AGENTS.md), or is METHODOLOGY.md itself what gets referenced in CLAUDE.md?

**Answer**: Both a and b. Include a brief line such as "This project uses the GRIPS methodology at version 1.0.0. For more info please visit..." and then also the reference to load the actual file(s) of the methodology.

---

## Question 29
**Asked by**: Dunkaroo Destroyer

**Question**: How does the METHODOLOGY.md file get loaded by agents? Should users add a reference to it in their CLAUDE.md (or AGENTS.md) like:

```markdown
# CLAUDE.md
@METHODOLOGY.md
```

Or does GRIPS have some other mechanism to ensure agents load the methodology when working on a project?

**Answer**: Yes, users should add `@METHODOLOGY.md` to their CLAUDE.md (or AGENTS.md).

---

## Question 30
**Asked by**: Dunkaroo Destroyer

**Question**: When a user runs `grips init` in their project, what exactly gets created? For example:

```
my-project/
├── METHODOLOGY.md         (created by grips init)
├── specs/                 (created by grips init)
│   ├── requirements/
│   │   ├── requirements.md
│   │   ├── qa/
│   │   └── adr/
│   ├── design/
│   │   ├── design.md
│   │   ├── qa/
│   │   └── adr/
│   └── implementation-plan/
│       ├── implementation-plan.md
│       ├── phase-0-prototype/
│       ├── qa/
│       └── adr/
```

Should `grips init` create stub/template files (like empty requirements.md, design.md, etc.), or just the directory structure? And does it also update the user's CLAUDE.md with `@METHODOLOGY.md`, or just tell them to do it manually?

**Answer**: The init command should create the directory structure and starting template files (containing very little, to start with). The rest should be built out as needed. Yes it should add the import of METHODOLOGY.md (and create a project local CLAUDE.md or AGENTS.md if it doesn't exist).

---

## Question 31
**Asked by**: Dunkaroo Destroyer

**Question**: When `grips init` needs to create or update the agent configuration file, how does it decide between CLAUDE.md and AGENTS.md? Should it:

a) Always prefer CLAUDE.md (since we're in Claude Code context)?
b) Detect which one exists and use that?
c) Ask the user which they prefer?
d) Support both by adding the reference to whichever exists, or creating CLAUDE.md if neither exists?

**Answer**: Instead of a `grips init` command, use a prompt to do these updates. That way whatever agent they are using can put it in the proper place.

---

## Question 32
**Asked by**: Dunkaroo Destroyer

**Question**: So if initialization is prompt-based rather than CLI-based, how do users get the GRIPS methodology files into `~/.grips/`? Is it:

a) Still provide a simple installer script/command that just downloads methodology files to ~/.grips/?
b) The initialization prompt itself instructs the agent to download/create the methodology files?
c) Users manually download from a website/GitHub?
d) Something else?

**Answer**: Yes, at the user level on a given machine, GRIPS installs into ~/.grips and versions are managed there. Adding GRIPS to a project is done with a prompt. Install custom commands for different agent systems. Detect the presence of those agents (Claude Code, Codex, etc.) in the user's home directory and offer to install custom commands to gripsify a project for each detected agent system.

---

## Question 33
**Asked by**: Dunkaroo Destroyer

**Question**: For the GRIPS installer that detects agent systems and installs custom commands:

a) What specific paths/files should it check to detect each agent system (e.g., for Claude Code, check for `~/.claude/` or something else)?

b) For Claude Code specifically, where do slash commands get installed? (I know they typically go in `.claude/commands/` in a project, but should the gripsify command be global in `~/.claude/commands/` or project-specific?)

c) Should the installer be a shell script, or something else?

**Answer**: The commands should be global, for Claude Code and for similar CLI products. Support Claude Code, Codex, OpenCode, and Gemini CLI to start.

---

## Question 34
**Asked by**: Dunkaroo Destroyer

**Question**: For the four agent systems you mentioned (Claude Code, Codex, OpenCode, and Gemini CLI), what are the specific paths for:

a) **Detection** - what path/file should the installer check to confirm each agent is installed?
b) **Global command installation** - where should the `/gripsify` command be installed for each system?

For example, for Claude Code:
- Detection: `~/.claude/` exists?
- Command installation: `~/.claude/commands/gripsify.md`?

**Answer**: For Claude Code, assume that their environment is just set up for what Claude Code does (so global commands go in `~/.claude/commands/`). Defer the specifics for the other agents (Codex, OpenCode, Gemini CLI) for now.

---

## Question 35
**Asked by**: Dunkaroo Destroyer

**Question**: When the `/gripsify` command creates the initial template files (requirements.md, design.md, implementation-plan.md), what should those templates contain? For example:

a) Completely empty files?
b) Minimal structure with headings like "# Requirements" and some placeholder text?
c) More detailed templates with sections pre-filled (like "## 1. Overview", "## 2. Core Features", etc.)?

What's the right balance between guidance and staying out of the way?

**Answer**: Call the command `/grips` (not `/gripsify`). Use option B - minimal structure with headings and placeholder text.

---

## Question 36
**Asked by**: Dunkaroo Destroyer

**Question**: Should the `specs/` directory and its contents be version-controlled (committed to git)? And what about the METHODOLOGY.md file - should that be in version control, or .gitignored since it just references ~/.grips/?

**Answer**: Yes, all of that is version controlled (both specs/ and METHODOLOGY.md).

---

## Question 37
**Asked by**: Dunkaroo Destroyer

**Question**: We've established that changes propagate through all layers. But what happens if an agent encounters a conflict or inconsistency during propagation? For example:

- A bug fix in code contradicts a stated requirement
- A design decision conflicts with an existing architectural constraint
- An implementation reveals that a requirement is technically infeasible

Should the agent:
a) Stop and ask the human for guidance?
b) Document the conflict in an ADR and propose a resolution?
c) Update all layers to resolve the conflict and note it in the commit?
d) Something else?

**Answer**: First clarify it with the human, unless the instructions are obviously a change. If clarified (or obvious) and no Q&A is required to clarify the request, then simply make the code changes and documentation changes in one go. If some back and forth is needed with the human to clarify or flesh out the requirements/design/etc. changes, then propose that to the human and confirm that they want to change the spec. At that point, we go back to the Q&A process, then update the specs docs as needed, then break down the work into the detailed implementation plan, and commit all of that before doing the implementation (which will then be separate commits).

---

## Question 38
**Asked by**: Dunkaroo Destroyer

**Question**: When a new version of GRIPS is released (say, 1.1.0), how should projects upgrade? Should they:

a) Manually update METHODOLOGY.md to point to the new version?
b) Have some kind of `grips upgrade` command?
c) Stay on their current version indefinitely (pin to specific version)?
d) Something else?

And are there any compatibility concerns between GRIPS versions that projects need to manage?

**Answer**: For now, assume that projects will stay on their current version indefinitely (pin to specific version). If needed, we will deal with upgrading the methodology later.

---

## Question 39
**Asked by**: Dunkaroo Destroyer

**Question**: We established that tests live outside the specs/ directory in language-specific locations. But how do tests relate to the GRIPS layers? For example:

a) Do tests get mentioned/specified in the implementation plan prompts?
b) Should there be a separate "test plan" layer in specs/?
c) Are tests just implementation details that agents handle as part of executing implementation plan steps?
d) Something else?

And how does GRIPS ensure test coverage stays synchronized with requirements/design/implementation?

**Answer**: Tests are part of the implementation. According to the methodology, the agent should include tests in the design, but the details of those tests, what they contain and how they operate, are specific to the product being built.

---

## Question 40
**Asked by**: Dunkaroo Destroyer

**Question**: What happens when someone wants to add GRIPS to an existing project that already has code but no specs? Should the `/grips` command:

a) Create empty specs and let the human/agent fill them in gradually?
b) Attempt to generate initial specs from the existing code?
c) Refuse to initialize and require manual spec creation first?
d) Something else?

**Answer**: Be permissive in the approach, but for now assume that we don't add GRIPS to any existing project (focus on new projects only for the initial version).

---

## Question 41
**Asked by**: Floppy Dog (unprompted clarification)

**Statement**: We need to define what is allowed and not allowed in each layer of the spec. In particular, the implementation plan (prompt plans) must never include code. There can be occasional references to specific files/classes/functions/variables in there, and of course the design may contain some significant naming and even schemas, but there should not be actual code in the prompt plans. Instead, they should contain descriptions of what to implement. The code is an implementation concern.

Include explicit and mandatory instructions about which concerns belong in which layer of the spec. Start with industry standards for what qualifies as requirements vs design vs plan.

**Acknowledged**: Layer separation is critical to GRIPS. Will define clear boundaries based on industry standards.

---

## Question 42
**Asked by**: Dunkaroo Destroyer

**Question**: For the layer separation boundaries, I want to clarify some potential gray areas:

**Data schemas/models** - You mentioned design can contain "significant naming and even schemas." Should the design include:
- Database schema definitions (table names, field names, types)?
- API request/response schemas (JSON structure)?
- Data class/model definitions (field names and types but not methods)?

**Configuration** - Where do things like:
- Environment variables
- Configuration file structures
- Build/deployment configurations

belong? Are these design concerns or implementation concerns?

**Error handling strategy** - If the design says "use exponential backoff for retries," is that appropriate level, or is that too implementation-specific?

**Answer**:
- **Database schemas**: Yes, but spec them the way an analyst would define fields and entities (not like DDL). Can have diagrams. For some technologies, use established paradigms such as CDM and LDM (requirements), PDM (design).
- **JSON structures**: Implementation concern, unless needed to define requirements (such as when integrating with an existing system).
- **Field names and types**: Fine in design.
- **Configuration**: Context-dependent:
  - User-facing configuration (product provides users ability to control things via env vars or config) = requirements concern
  - Build/deployment configurations = depends on the product (if building a CICD system, then requirements; if mobile app, then design or implementation)
  - Internal configuration = implementation concern
- **Error handling strategy** (like "use exponential backoff for retries"): Design concern, unless what we're building is specifically related to API integration, in which case it could be requirements.

**Key principle**: Layer assignment is context-dependent based on what the product is and what problem it's solving.

---

## Question 43
**Asked by**: Dunkaroo Destroyer

**Question**: Based on industry standards and what you've described, let me propose the core concerns for each layer:

**Requirements Layer** - WHAT and WHY:
- Business goals and user needs
- Functional requirements (what the system must do)
- Non-functional requirements (performance, security, scalability)
- User-facing features and behavior
- External integrations and constraints
- Data models at conceptual level (CDM/LDM - entities and relationships)
- User-facing configuration options

**Design Layer** - HOW (architecture and approach):
- System architecture and component breakdown
- Technology choices and frameworks
- Data models at physical level (PDM - actual schemas, field names, types)
- API design and interfaces
- Module/component interactions and dependencies
- Error handling strategies
- Testing strategy (what to test, coverage goals)
- Security approach and patterns

**Implementation Plan Layer** - STEPS (actionable prompts):
- Phased breakdown of work (prototype → MVP → features)
- Step-by-step instructions for agents
- Files to create/modify
- Tasks and verification checklists
- References to specific classes/functions/variables where needed
- NO actual code, only descriptions of what to implement

Is this breakdown correct? Anything missing or misplaced?

**Answer**: "Files to create/modify" sounds like an implementation concern, not planning - unless it's talking about modifying existing file(s) related to a specific change. The rest looks good.

---

## Question 44
**Asked by**: Dunkaroo Destroyer

**Question**: I notice in your earlier implementation plan example (Question 15), you had sections like:

```
### Step 1.1: Add CoreData Stack

**Files Created**:
- Services/CoreDataStack.swift
- VocabReader.xcdatamodeld

**Files Modified**:
- VocabReaderApp.swift
```

But you just said "Files to create/modify" is an implementation concern. Should the implementation plan steps:

a) Still include these file lists as context/scope (like in your example)?
b) Remove file lists entirely from implementation plans?
c) Only list files being modified (not created)?
d) Something else?

Or is the distinction that listing affected files is okay as context, but the implementation plan shouldn't dictate file structure/organization?

**Answer**: A - still include file lists as context/scope (like in the example).

---

## Current Understanding

### Core Concept
GRIPS is a methodology for maintaining a living, synchronized hierarchy of project artifacts where changes propagate bidirectionally through all layers.

### Directory Structure
```
specs/
├── requirements/
│   ├── requirements.md (single file until >1000 lines)
│   ├── [1-feature-name.md, 2-another-feature.md, ...] (when split)
│   ├── qa/
│   │   ├── 0.0.1-topic.md
│   │   ├── 0.0.2-topic.md
│   │   └── 1.0.1-topic.md
│   └── adr/
│       ├── 0.0.1-decision.md
│       └── 1.0.1-decision.md
├── design/
│   ├── design.md (includes architecture)
│   ├── [numbered files when >1000 lines]
│   ├── qa/
│   └── adr/
└── implementation-plan/
    ├── implementation-plan.md
    ├── phase-0-prototype/
    │   ├── 1-feature.md
    │   └── 2-feature.md
    ├── phase-1-mvp/
    ├── phase-2-expansion/
    ├── qa/
    └── adr/
```

### Key Principles
1. **All changes must propagate through ALL layers** (strict layer discipline)
2. **Bidirectional propagation based on origin**: Changes flow UP (code→implementation plan→design→requirements), DOWN (requirements→design→implementation plan→code), or BOTH ways depending on where the change originates
3. **Agent must identify change origin layer** before starting work to determine propagation direction
4. **Two-path workflow based on change complexity**:
   - **Simple/Obvious Changes**: If no Q&A needed (change is obvious or already clarified) → Make code changes and documentation changes together in one commit
   - **Complex Changes Requiring Spec Updates**: If back-and-forth needed to clarify/flesh out → Propose spec change to human and get confirmation → Q&A process → Update specs docs → Create detailed implementation plan → Commit all spec/plan changes → Then implement in separate commits
5. **Spec review workflow for complex changes**:
   - Phase 1 (Spec Review): Update requirements, design, and implementation plan together → Review cycles with Critic Markup → Multiple commits (agent changes + human feedback rounds) → Human approval
   - Phase 2 (Implementation): Execute implementation plan steps → Each step gets one commit including code changes, status updates, and any clarifications to specs discovered during implementation → Bug fixes and small tweaks can be separate commits as guided by human
6. **Conflict resolution**: When encountering conflicts/inconsistencies, clarify with human unless change is obvious → For simple changes, proceed with code+docs in one commit → For complex changes requiring spec updates, confirm with human before starting Q&A process
7. **Files split at 1000 line threshold**
8. **Outline numbering for all sections**
9. **Implementation plans organized by phases** (0.0 = prototype, 1.0 = MVP, 2.0+ = expansion)
10. **Implementation plans contain executable prompts** with detailed TASKS, REQUIREMENTS, and VERIFICATION checklists
11. **Agents draft all docs; humans review using Critic Markup**
12. **Critic Markup review workflow**: Agent evaluates feedback and either (a) resolves simple changes immediately by removing the comment, or (b) makes the change AND replies to the comment if it's complicated or requires decision-making
13. **Q&A sessions are documented continuously** and live in qa/ subdirectories within each layer
14. **Q&A and ADR versioning** uses semantic-style numbering (0.0.1, 0.0.2, 1.0.1, etc.)
15. **Status tracking is single source of truth** (no diary-like release notes mixed in)
16. **All project artifacts version controlled**: Both specs/ directory and METHODOLOGY.md are committed to version control
17. **GRIPS installation**: Methodology stored in ~/.grips/ with versioned directories (e.g., ~/.grips/1.0.0/methodology.md), projects reference via METHODOLOGY.md file
18. **Version pinning**: Projects stay on their current GRIPS version indefinitely (methodology upgrade path to be determined later)
19. **Agent integration**: /grips command for Claude Code (in ~/.claude/commands/), creates minimal template files with headings and placeholder text
20. **Testing approach**: Tests are part of implementation; design layer specifies what to test, implementation phase contains actual test code (product-specific)
21. **New projects only**: Initial version focuses on new projects; adding GRIPS to existing projects deferred to future versions
22. **Strict layer separation concerns**: Each layer has explicit boundaries for what belongs there (based on industry standards for requirements/design/planning) - implementation plans must NEVER include actual code, only descriptions of what to implement
23. **Context-dependent layer assignment**: What belongs in which layer depends on what the product is and what problem it's solving (e.g., CICD config is requirements for a CICD product, but design/implementation for a mobile app)
24. **Data modeling standards**: Use established paradigms where applicable (CDM/LDM for requirements, PDM for design) - schemas defined analyst-style with entities/fields/types, not code (no DDL)
25. **Layer concern breakdown**:
   - **Requirements** (WHAT/WHY): Business goals, functional/non-functional requirements, user-facing features, external integrations, conceptual data models (CDM/LDM), user-facing configuration
   - **Design** (HOW): Architecture, technology choices, physical data models (PDM), API design, component interactions, error handling strategies, testing strategy, security patterns
   - **Implementation Plan** (STEPS): Phased work breakdown, step-by-step agent instructions, task/verification checklists, affected file lists (as context/scope), references to specific code elements, NO actual code - only descriptions

### Open Questions
- Should section numbers synchronize across layers?
- Should status tracking be isolated from implementation plan docs?
- How to handle linking/traceability (deferred for now)

---

**Last Updated**: 2026-01-06 (Question 44)
